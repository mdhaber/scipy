{
    "Normal": "\nNormal distribution with prescribed mean and standard deviation.\n\nThe probability density function of the normal distribution is:\n\n.. math::\n\n    f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp {\n        \\left( -\\frac{1}{2}\\left( \\frac{x - \\mu}{\\sigma} \\right)^2 \\right)}\n\nfor :math:`x` in (-\u221e, \u221e).\nThis class accepts one parameterization:\n`mu` for :math:`\u00b5 \u2208 (-\u221e, \u221e)`, `sigma` for :math:`\u03c3 \u2208 (0, \u221e)`.\n\n\nParameters\n----------\ntol : positive float, optional\n    The desired relative tolerance of calculations. Left unspecified,\n    calculations may be faster; when provided, calculations may be\n    more likely to meet the desired accuracy.\niv_policy : {None, \"skip_all\"}\n    Specifies the level of input validation to perform. Left unspecified,\n    input validation is performed to ensure appropriate behavior in edge\n    case (e.g. parameters out of domain, argument outside of distribution\n    support, etc.) and improve consistency of output dtype, shape, etc.\n    Pass ``'skip_all'`` to avoid the computational overhead of these\n    checks when rough edges are acceptable.\ncache_policy : {None, \"no_cache\"}\n    Specifies the extent to which intermediate results are cached. Left\n    unspecified, intermediate results of some calculations (e.g. distribution\n    support, moments, etc.) are cached to improve performance of future\n    calculations. Pass ``'no_cache'`` to reduce memory reserved by the class\n    instance.\nrng : numpy.random.Generator\n    Random number generator to be used by any methods that require\n    pseudo-random numbers (e.g. `sample`).\n\nNotes\n-----\nThe following abbreviations are used throughout the documentation.\n\n- PDF: probability density function\n- CDF: cumulative distribution function\n- CCDF: complementary CDF\n- entropy: differential entropy\n- log-*F*: logarithm of *F* (e.g. log-CDF)\n- inverse *F*: inverse function of *F* (e.g. inverse CDF)\n\nThe API documentation is written to describe the API, not to serve as\na statistical reference. Effort is made to be correct at the level\nrequired to use the functionality, not to be mathematically rigorous.\nFor example, continuity and differentiability may be implicitly assumed.\nFor precise mathematical definitions, consult your preferred mathematical\ntext.\n\nExamples\n--------\nTo use the distribution class, it must be instantiated using keyword\nparameters corresponding with one of the accepted parameterizations.\n\n>>> import numpy as np\n>>> import matplotlib.pyplot as plt\n>>> from scipy import stats\n>>> from scipy.stats import Normal\n>>> X = Normal(mu=-0.81, sigma=0.69)\n\nFor convenience, the ``plot`` method can be used to visualize the density\nand other functions of the distribution.\n\n>>> X.plot()\n>>> plt.show()\n\nThe support of the underlying distribution is available using the ``support``\nmethod.\n\n>>> X.support()\n(-inf, inf)\n\nThe numerical values of parameters associated with all parameterizations\nare available as attributes.\n\n>>> X.mu, X.sigma\n(-0.81, 0.69)\n\nTo evaluate the probability density function of the underlying distribution\nat argument ``x=-1.13``:\n\n>>> x = -1.13\n>>> X.pdf(x)\n0.5192263911374636\n\nThe cumulative distribution function, its complement, and the logarithm\nof these functions are evaluated similarly.\n\n>>> np.allclose(np.exp(X.logccdf(x)), 1 - X.cdf(x))\nTrue\n\nThe inverse of these functions with respect to the argument ``x`` is also\navailable.\n\n>>> logp = np.log(1 - X.ccdf(x))\n>>> np.allclose(X.ilogcdf(logp), x)\nTrue\n\nNote that distribution functions and their logarithms also have two-argument\nversions for working with the probability mass between two arguments. The\nresult tends to be more accurate than the naive implementation because it avoids\nsubtractive cancellation.\n\n>>> y = -0.56\n>>> np.allclose(X.ccdf(x, y), 1 - (X.cdf(y) - X.cdf(x)))\nTrue\n\nThere are methods for computing measures of central tendency,\ndispersion, higher moments, and entropy.\n\n>>> X.mean(), X.median(), X.mode()\n(-0.81, -0.81, -0.81)\n>>> X.variance(), X.standard_deviation()\n(0.4760999999999999, 0.69)\n>>> X.skewness(), X.kurtosis()\n(0.0, 3.0)\n>>> np.allclose(X.moment(order=6, kind='standardized'),\n...             X.moment(order=6, kind='central') / X.variance()**3)\nTrue\n>>> np.allclose(np.exp(X.logentropy()), X.entropy())\nTrue\n\nPseudo-random and quasi-Monte Carlo samples can be drawn from\nthe underlying distribution using ``sample``.\n\n>>> rng = np.random.default_rng(2354873452)\n>>> X.sample(shape=(4,), rng=rng)\narray([-1.62449664, -1.00878072, -0.70469216, -1.48426691])\n>>> n = 200\n>>> s = X.sample(shape=(n,), rng=rng, qmc_engine=stats.qmc.Halton)\n>>> assert np.count_nonzero(s < X.median()) == n/2\n\n\nAttributes\n----------\nAll parameters are available as attributes.\n\nMethods\n-------\nsupport\nplot\nsample\nfit\nmoment\nmean\nmedian\nmode\nvariance\nstandard_deviation\nskewness\nkurtosis\npdf\nlogpdf\ncdf\nicdf\nccdf\niccdf\nlogcdf\nilogcdf\nlogccdf\nilogccdf\nentropy\nlogentropy\n",
    "Uniform": "\nUniform distribution.\n\nThe probability density function of the uniform distribution is:\n\n.. math::\n\n    f(x; a, b) = \\frac{1}\n                      {b - a}\n\nfor :math:`x` in (a, b).\nThis class accepts one parameterization:\n`a` for :math:`a \u2208 (-\u221e, \u221e)`, `b` for :math:`b \u2208 (a, \u221e)`.\n\n\nParameters\n----------\ntol : positive float, optional\n    The desired relative tolerance of calculations. Left unspecified,\n    calculations may be faster; when provided, calculations may be\n    more likely to meet the desired accuracy.\niv_policy : {None, \"skip_all\"}\n    Specifies the level of input validation to perform. Left unspecified,\n    input validation is performed to ensure appropriate behavior in edge\n    case (e.g. parameters out of domain, argument outside of distribution\n    support, etc.) and improve consistency of output dtype, shape, etc.\n    Pass ``'skip_all'`` to avoid the computational overhead of these\n    checks when rough edges are acceptable.\ncache_policy : {None, \"no_cache\"}\n    Specifies the extent to which intermediate results are cached. Left\n    unspecified, intermediate results of some calculations (e.g. distribution\n    support, moments, etc.) are cached to improve performance of future\n    calculations. Pass ``'no_cache'`` to reduce memory reserved by the class\n    instance.\nrng : numpy.random.Generator\n    Random number generator to be used by any methods that require\n    pseudo-random numbers (e.g. `sample`).\n\nNotes\n-----\nThe following abbreviations are used throughout the documentation.\n\n- PDF: probability density function\n- CDF: cumulative distribution function\n- CCDF: complementary CDF\n- entropy: differential entropy\n- log-*F*: logarithm of *F* (e.g. log-CDF)\n- inverse *F*: inverse function of *F* (e.g. inverse CDF)\n\nThe API documentation is written to describe the API, not to serve as\na statistical reference. Effort is made to be correct at the level\nrequired to use the functionality, not to be mathematically rigorous.\nFor example, continuity and differentiability may be implicitly assumed.\nFor precise mathematical definitions, consult your preferred mathematical\ntext.\n\nExamples\n--------\nTo use the distribution class, it must be instantiated using keyword\nparameters corresponding with one of the accepted parameterizations.\n\n>>> import numpy as np\n>>> import matplotlib.pyplot as plt\n>>> from scipy import stats\n>>> from scipy.stats import Uniform\n>>> X = Uniform(a=0.09, b=188.73)\n\nFor convenience, the ``plot`` method can be used to visualize the density\nand other functions of the distribution.\n\n>>> X.plot()\n>>> plt.show()\n\nThe support of the underlying distribution is available using the ``support``\nmethod.\n\n>>> X.support()\n(0.09, 188.73)\n\nThe numerical values of parameters associated with all parameterizations\nare available as attributes.\n\n>>> X.a, X.b, X.ab\n(0.09, 188.73, 188.64)\n\nTo evaluate the probability density function of the underlying distribution\nat argument ``x=60.45``:\n\n>>> x = 60.45\n>>> X.pdf(x)\n0.005301102629346905\n\nThe cumulative distribution function, its complement, and the logarithm\nof these functions are evaluated similarly.\n\n>>> np.allclose(np.exp(X.logccdf(x)), 1 - X.cdf(x))\nTrue\n\nThe inverse of these functions with respect to the argument ``x`` is also\navailable.\n\n>>> logp = np.log(1 - X.ccdf(x))\n>>> np.allclose(X.ilogcdf(logp), x)\nTrue\n\nNote that distribution functions and their logarithms also have two-argument\nversions for working with the probability mass between two arguments. The\nresult tends to be more accurate than the naive implementation because it avoids\nsubtractive cancellation.\n\n>>> y = 120.82\n>>> np.allclose(X.ccdf(x, y), 1 - (X.cdf(y) - X.cdf(x)))\nTrue\n\nThere are methods for computing measures of central tendency,\ndispersion, higher moments, and entropy.\n\n>>> X.mean(), X.median(), X.mode()\n(94.41000000000001, 94.41, 94.41)\n>>> X.variance(), X.standard_deviation()\n(2965.4208, 54.4556773899655)\n>>> X.skewness(), X.kurtosis()\n(-1.182253748070285e-15, 1.7999999999999996)\n>>> np.allclose(X.moment(order=6, kind='standardized'),\n...             X.moment(order=6, kind='central') / X.variance()**3)\nTrue\n>>> np.allclose(np.exp(X.logentropy()), X.entropy())\nTrue\n\nPseudo-random and quasi-Monte Carlo samples can be drawn from\nthe underlying distribution using ``sample``.\n\n>>> rng = np.random.default_rng(2354873452)\n>>> X.sample(shape=(4,), rng=rng)\narray([161.627692  ,  27.17787751,  49.56323663,  38.16222048])\n>>> n = 200\n>>> s = X.sample(shape=(n,), rng=rng, qmc_engine=stats.qmc.Halton)\n>>> assert np.count_nonzero(s < X.median()) == n/2\n\n\nAttributes\n----------\nAll parameters are available as attributes.\n\nMethods\n-------\nsupport\nplot\nsample\nfit\nmoment\nmean\nmedian\nmode\nvariance\nstandard_deviation\nskewness\nkurtosis\npdf\nlogpdf\ncdf\nicdf\nccdf\niccdf\nlogcdf\nilogcdf\nlogccdf\nilogccdf\nentropy\nlogentropy\n",
    "LogUniform": "\nLog-uniform distribution.\n\nThe probability density function of the log-uniform distribution is:\n\n.. math::\n\n    f(x; a, b) = \\frac{1}\n                      {x (\\log(b) - \\log(a))}\n\nIf :math:`\\log(X)` is a random variable that follows a uniform distribution\nbetween :math:`\\log(a)` and :math:`\\log(b)`, then :math:`X` is log-uniformly\ndistributed with shape parameters :math:`a` and :math:`b`.\n\nfor :math:`x` in [a, b].\nThis class accepts two parameterizations:\n\n- `log_a` for :math:`\\log(a) \u2208 (-\u221e, \u221e)`, `log_b` for :math:`\\log(b) \u2208 (\\log(a), \u221e)`\n- `a` for :math:`a \u2208 (0, \u221e)`, `b` for :math:`b \u2208 (a, \u221e)`\n\n\nParameters\n----------\ntol : positive float, optional\n    The desired relative tolerance of calculations. Left unspecified,\n    calculations may be faster; when provided, calculations may be\n    more likely to meet the desired accuracy.\niv_policy : {None, \"skip_all\"}\n    Specifies the level of input validation to perform. Left unspecified,\n    input validation is performed to ensure appropriate behavior in edge\n    case (e.g. parameters out of domain, argument outside of distribution\n    support, etc.) and improve consistency of output dtype, shape, etc.\n    Pass ``'skip_all'`` to avoid the computational overhead of these\n    checks when rough edges are acceptable.\ncache_policy : {None, \"no_cache\"}\n    Specifies the extent to which intermediate results are cached. Left\n    unspecified, intermediate results of some calculations (e.g. distribution\n    support, moments, etc.) are cached to improve performance of future\n    calculations. Pass ``'no_cache'`` to reduce memory reserved by the class\n    instance.\nrng : numpy.random.Generator\n    Random number generator to be used by any methods that require\n    pseudo-random numbers (e.g. `sample`).\n\nNotes\n-----\nThe following abbreviations are used throughout the documentation.\n\n- PDF: probability density function\n- CDF: cumulative distribution function\n- CCDF: complementary CDF\n- entropy: differential entropy\n- log-*F*: logarithm of *F* (e.g. log-CDF)\n- inverse *F*: inverse function of *F* (e.g. inverse CDF)\n\nThe API documentation is written to describe the API, not to serve as\na statistical reference. Effort is made to be correct at the level\nrequired to use the functionality, not to be mathematically rigorous.\nFor example, continuity and differentiability may be implicitly assumed.\nFor precise mathematical definitions, consult your preferred mathematical\ntext.\n\nExamples\n--------\nTo use the distribution class, it must be instantiated using keyword\nparameters corresponding with one of the accepted parameterizations.\n\n>>> import numpy as np\n>>> import matplotlib.pyplot as plt\n>>> from scipy import stats\n>>> from scipy.stats import LogUniform\n>>> X = LogUniform(log_a=-2.72, log_b=0.64)\n\nFor convenience, the ``plot`` method can be used to visualize the density\nand other functions of the distribution.\n\n>>> X.plot()\n>>> plt.show()\n\nThe support of the underlying distribution is available using the ``support``\nmethod.\n\n>>> X.support()\n(0.06587475442640295, 1.8964808793049515)\n\nThe numerical values of parameters associated with all parameterizations\nare available as attributes.\n\n>>> X.a, X.b, X.log_a, X.log_b\n(0.06587475442640295, 1.8964808793049515, -2.72, 0.64)\n\nTo evaluate the probability density function of the underlying distribution\nat argument ``x=0.19``:\n\n>>> x = 0.19\n>>> X.pdf(x)\n1.5664160401002505\n\nThe cumulative distribution function, its complement, and the logarithm\nof these functions are evaluated similarly.\n\n>>> np.allclose(np.exp(X.logccdf(x)), 1 - X.cdf(x))\nTrue\n\nThe inverse of these functions with respect to the argument ``x`` is also\navailable.\n\n>>> logp = np.log(1 - X.ccdf(x))\n>>> np.allclose(X.ilogcdf(logp), x)\nTrue\n\nNote that distribution functions and their logarithms also have two-argument\nversions for working with the probability mass between two arguments. The\nresult tends to be more accurate than the naive implementation because it avoids\nsubtractive cancellation.\n\n>>> y = 0.57\n>>> np.allclose(X.ccdf(x, y), 1 - (X.cdf(y) - X.cdf(x)))\nTrue\n\nThere are methods for computing measures of central tendency,\ndispersion, higher moments, and entropy.\n\n>>> X.mean(), X.median(), X.mode()\n(0.544823251451949, 0.35345468195878005, 0.06587475442640298)\n>>> X.variance(), X.standard_deviation()\n(0.23773611311460957, 0.4875819040065059)\n>>> X.skewness(), X.kurtosis()\n(1.0901044819654708, 3.106819336127329)\n>>> np.allclose(X.moment(order=6, kind='standardized'),\n...             X.moment(order=6, kind='central') / X.variance()**3)\nTrue\n>>> np.allclose(np.exp(X.logentropy()), X.entropy())\nTrue\n\nPseudo-random and quasi-Monte Carlo samples can be drawn from\nthe underlying distribution using ``sample``.\n\n>>> rng = np.random.default_rng(2354873452)\n>>> X.sample(shape=(4,), rng=rng)\narray([1.17030183, 0.10672299, 0.15900855, 0.12978593])\n>>> n = 200\n>>> s = X.sample(shape=(n,), rng=rng, qmc_engine=stats.qmc.Halton)\n>>> assert np.count_nonzero(s < X.median()) == n/2\n\n\nAttributes\n----------\nAll parameters are available as attributes.\n\nMethods\n-------\nsupport\nplot\nsample\nfit\nmoment\nmean\nmedian\nmode\nvariance\nstandard_deviation\nskewness\nkurtosis\npdf\nlogpdf\ncdf\nicdf\nccdf\niccdf\nlogcdf\nilogcdf\nlogccdf\nilogccdf\nentropy\nlogentropy\n"
}